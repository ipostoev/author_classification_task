{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97e95ec-9f7a-460e-8611-53e34f4e299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Загружаем библиотеки и данные\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import norm\n",
    " \n",
    "data = load_iris()\n",
    "X, y, column_names = data['data'], data['target'], data['feature_names']\n",
    "X = pd.DataFrame(X, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4fe979-7e4e-488d-ab3b-8accd9dfb72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igorpostoev/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### Разбиваем данные\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=44)\n",
    " \n",
    "means = X_train.groupby(y_train).apply(np.mean)\n",
    "stds = X_train.groupby(y_train).apply(np.std)\n",
    " \n",
    "### Вычисляем априорную вероятность класса\n",
    "probs = X_train.groupby(y_train).apply(lambda x: len(x)) / X_train.shape[0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77c35f-a534-4009-a3c5-baf627dfd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Вычисляем вероятность для Теоремы Байеса для каждого элемента\n",
    "y_pred = []\n",
    "# каждый элемент в валидационной части данных\n",
    "for elem in range(X_val.shape[0]):\n",
    "   p = {}\n",
    " \n",
    "   # для каждого возможного класса\n",
    "   for cl in np.unique(y_train):\n",
    " \n",
    "       # априорная вероятность взятого ранее класса\n",
    "       p[cl] = probs.iloc[cl]\n",
    " \n",
    "       # для каждого столбца в датасете\n",
    "       for index, param in enumerate(X_val.iloc[elem]):\n",
    " \n",
    "           # умножаем вероятность того, что данное значение столбца\n",
    "           # будет принадлежать распределению для выбранного класса\n",
    "           p[cl] *= norm.pdf(param, means.iloc[cl, index], stds.iloc[cl, index])\n",
    "  \n",
    "   y_pred.append(pd.Series(p).values.argmax())\n",
    " \n",
    "### Посмотрим точность нашего предсказания несколькими методами\n",
    "# ручной классификатор\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy1 = accuracy_score(y_val, y_pred)\n",
    " \n",
    "# классификатор из библиотеки sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "accuracy2 = accuracy_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c58cff-1a72-458b-b5cc-e50e05b753af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b6be8-fc7c-4172-a2f4-14ed96ab2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    " # для начала определяется малый набор данных с произвольно взятой длиной словаря мешка слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6f1ca86d-6d4d-4a6f-a6e3-72b961a3443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.array([[0, 1, 0],\n",
    "                                   [0, 0, 1],\n",
    "                                   [0, 0, 1],\n",
    "                                   [1, 1, 0],\n",
    "                                   [1, 0, 1],\n",
    "                                    [0, 0, 0]]))\n",
    "y_train = np.array([0, 1, 1, 0, 1, 0])\n",
    "\n",
    "X_val = pd.DataFrame(np.array([[0, 1, 0],\n",
    "                               [0, 0, 1]]))\n",
    "y_val = np.array([0, 1])\n",
    "\n",
    "#P(Y)\n",
    "aprior_class_probs = X_train.groupby(y_train).apply((lambda x: len(x))) / len(X_train)\n",
    "\n",
    "#P(X|Y) / P(X)\n",
    "aprior_feature_probs = {}\n",
    "for feature in X_train.columns:\n",
    "    aprior_feature_probs[feature] = np.count_nonzero(X_train[feature].values == 1)\n",
    "\n",
    "groups = X_train.groupby(y_train).groups\n",
    "w_prob_by_cl = {}\n",
    "for cl in np.unique(y_train):\n",
    "    w_prob_by_cl[cl] = {}\n",
    "    for feature in X_val.columns:\n",
    "        cond_feature_p = np.count_nonzero(X_train.iloc[groups[cl]][feature].values == 1)\n",
    "        cond_feature_p = cond_feature_p / aprior_feature_probs[feature]\n",
    "        w_prob_by_cl[cl][feature] = cond_feature_p\n",
    "    \n",
    "y_pred = []\n",
    "for entry in range(len(X_val.values)):\n",
    "    p = {}\n",
    "    \n",
    "    # определение условной вероятности каждого класса при наличии признаков P(Y|X)\n",
    "    for cl in np.unique(y_val):\n",
    "        # априорная вероятность класса - отношения вхождений соответствующих данному классу ко всем вхождениям P(Y)\n",
    "        p[cl] = aprior_class_probs[cl]\n",
    "        \n",
    "        # апостериорная вероятность всех признаков при данном классе равна\n",
    "        # произведению(сейчас сумма, т к если одного из слов не будет в предложении, вероятность всего класса будет 0)\n",
    "        # условных вероятностей для каждого признака по отдельности (потому алгоритм и называют \"наивным\")\n",
    "        \n",
    "        # условная вероятность в данном случае - отношение количества вхождений, содержащих данный признак к общему количеству вхождений(для данного класса)\n",
    "        for feature in X_val.columns:\n",
    "            if X_val.iloc[entry][feature] == 1:\n",
    "                p[cl] += w_prob_by_cl[cl][feature]\n",
    "                print(f\"{cl}:{feature} - {p[cl]}\")\n",
    "        \n",
    "    y_pred.append(pd.Series(p).values.argmax())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
